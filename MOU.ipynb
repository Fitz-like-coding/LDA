{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = ['literary', 'literature', 'authors', 'century', 'texts', 'writers', 'economic', 'critique']\n",
    "doc_term = np.array([[0,0,0,4,0,0,2,5],\n",
    "                    [0,0,0,0,0,0,6,11],\n",
    "                    [0,0,0,3,0,0,8,0],\n",
    "                    [0,0,0,2,1,0,6,16],\n",
    "                    [0,1,0,5,1,0,3,13],\n",
    "                    [0,0,0,0,0,0,5,6],\n",
    "                    [10,3,0,4,0,1,0,0],\n",
    "                    [13,1,7,0,0,5,0,0],\n",
    "                    [7,3,0,4,1,8,0,0],\n",
    "                    [20,14,3,0,0,0,0,0],\n",
    "                    [5,6,5,0,0,10,0,0],\n",
    "                    [9,7,0,2,0,1,0,0],\n",
    "                    [3,5,3,0,0,6,0,0],\n",
    "                    [8,13,3,1,1,3,0,0],\n",
    "                    [9,3,4,0,0,6,0,0],\n",
    "                    [11,7,4,0,1,6,0,0],\n",
    "                    [2,3,0,1,1,1,0,0],\n",
    "                    [5,2,13,0,0,5,0,0],\n",
    "                    [7,3,6,1,0,11,0,0],\n",
    "                    [5,9,8,2,0,4,0,0]])\n",
    "K = 2\n",
    "V = 8\n",
    "# Alpha = [1] * K\n",
    "# Beta = [[1] * V] * K\n",
    "Alpha = 1\n",
    "Beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1.76368128e-01 4.16443022e-01 3.73851146e-05 1.17668808e-01\n  5.18736312e-02 3.16661272e-02 6.73677889e-02 1.38575110e-01]\n [7.83659131e-02 1.19995567e-01 8.42399284e-02 1.79208850e-01\n  3.54616815e-02 3.26314563e-01 4.30543290e-03 1.72108064e-01]]\n[[0.29751149 0.70248851]]\n"
    }
   ],
   "source": [
    "Phi = dirichlet.rvs([Beta]*V, size=K, random_state=1)\n",
    "Theta = dirichlet.rvs([Alpha]*K, random_state=1)\n",
    "print (Phi)\n",
    "print (Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851],\n       [0.29751149, 0.70248851]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = [[Alpha]*K] * doc_term.shape[0] * Theta\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 0\n",
    "while itr <= 600:\n",
    "    # update Phi and Beta\n",
    "    e = Beta + np.multiply(doc_term, Z.T.reshape(K, doc_term.shape[0],1)).sum(axis=1) - 1 + 0.1\n",
    "    \n",
    "    for k in range(len(e)):\n",
    "        Phi[k] = dirichlet.rvs(e[k], random_state=None)\n",
    "\n",
    "    # update Z\n",
    "    temp = np.power(np.repeat(Phi.reshape(Phi.shape[0], -1, Phi.shape[1]), doc_term.shape[0], axis=1), doc_term)\n",
    "    temp = np.prod(temp,axis=2)\n",
    "    Z = np.multiply(temp, Z.T).T \n",
    "    Z = Z/Z.sum(axis=1,keepdims=True)\n",
    "\n",
    "    # update Theta\n",
    "    d = Alpha + Z.sum(axis=0, keepdims=True)\n",
    "    Theta = dirichlet.rvs(d[0], random_state=None)\n",
    "\n",
    "    itr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "topic  0\ncritique 0.4560440612407665\neconomic 0.3199117308964672\ncentury 0.1446000219640655\nliterature 0.03764119291629742\ntexts 0.02771147935136703\n\ntopic  1\nliterary 0.33159525751621516\nliterature 0.22276496339951887\nwriters 0.21870728876786133\nauthors 0.15981416496241974\ncentury 0.04858746751812226\n\n"
    }
   ],
   "source": [
    "#topic words distribution\n",
    "for k, p in enumerate(Phi):\n",
    "    print ('topic ',k)\n",
    "    for w in np.argsort(p)[::-1][:5]:\n",
    "        print (vocabulary[w], p[w])\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Docs Topic0 Topic1\n0 [1. 0.]\n1 [1. 0.]\n2 [1. 0.]\n3 [1. 0.]\n4 [1. 0.]\n5 [1. 0.]\n6 [0. 1.]\n7 [0. 1.]\n8 [0. 1.]\n9 [0. 1.]\n10 [0. 1.]\n11 [0. 1.]\n12 [0. 1.]\n13 [0. 1.]\n14 [0. 1.]\n15 [0. 1.]\n16 [0. 1.]\n17 [0. 1.]\n18 [0. 1.]\n19 [0. 1.]\n"
    }
   ],
   "source": [
    "#doc topic distribution\n",
    "print ('Docs Topic0 Topic1' )\n",
    "for i in range(len(Z)):\n",
    "    print (i, Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.01"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}